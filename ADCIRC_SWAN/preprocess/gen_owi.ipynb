{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and coverting ERA5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on the fifth generation ECMWF atmospheric reanalysis of the global climate ERA5 is found at:\n",
    "https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Requesting ERA5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Go to the ERA5 hourly data on single levels from 1979 to present (https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=form)\n",
    "\n",
    "b) In product type select Reanalysis\n",
    "\n",
    "c) In Variable select Popular -> 10m u-component of wind, 10m v-component of wind, and Mean sea level pressure.\n",
    "\n",
    "d) In this example we will prepare the data for Hurricane Arthur, from 06/27/2014 to 07/09/2014. Therefore, we will have to download 2 ERA5 files, one from 06/27/2014 to 06/30/2014 and another from 07/01/2014 to 07/09/2014. \n",
    "\n",
    "First, we will download the data from 06/27/2014 to 06/30/2014. To do that we just need to select the Year, Month and Day accordingly. We will work with inputs every 6 hours, so select the Time: 00:00, 06:00, 12:00, and 18:00.\n",
    "\n",
    "e) In the Geographical area tab select “Whole available region”\n",
    "\n",
    "f) Select the GRIB format in the Format tab.\n",
    "\n",
    "g) Click on “Show API request” and save the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Downloading ERA5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary lybraries:\n",
    "\n",
    "\n",
    "cfgrib is installed as:\n",
    "conda install -c conda-forge cfgrib\n",
    "xarray is installed as:\n",
    "conda install -c conda-forge xarray dask netCDF4 bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,getopt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import numpy.core.multiarray \n",
    "import netCDF4 as nc4\n",
    "import xarray as xr\n",
    "import scipy.interpolate\n",
    "import cdsapi\n",
    "import datetime\n",
    "c = cdsapi.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste the API request and start downloading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = np.arange(0,15).astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-17 16:54:00,482 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2020-09-17 16:54:01,185 INFO Request is queued\n",
      "2020-09-17 16:54:03,896 INFO Request is running\n",
      "2020-09-17 16:54:51,252 INFO Request is completed\n",
      "2020-09-17 16:54:51,252 INFO Downloading http://136.156.132.153/cache-compute-0002/cache/data8/adaptor.mars.internal-1600376042.9561675-16504-6-5262ec3d-6c6b-4902-b3bf-0ffb3499925c.grib to download.grib (998.1M)\n",
      "2020-09-17 16:58:55,789 INFO Download rate 4.1M/s                                                                      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(content_length=1046606400,content_type=application/x-grib,location=http://136.156.132.153/cache-compute-0002/cache/data8/adaptor.mars.internal-1600376042.9561675-16504-6-5262ec3d-6c6b-4902-b3bf-0ffb3499925c.grib)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = ['00:00', '02:00', '04:00','06:00', '08:00', '10:00',\n",
    "        '12:00', '14:00', '16:00','18:00', '20:00', '22:00',]\n",
    "        #'12:00', '13:00', '14:00','15:00', '16:00', '17:00',\n",
    "        #'18:00', '19:00', '20:00','21:00', '22:00', '23:00',]\n",
    "        #\n",
    "c.retrieve(\n",
    "    'reanalysis-era5-single-levels',\n",
    "    {\n",
    "        'product_type': 'reanalysis',\n",
    "        'format': 'grib',\n",
    "        'variable': [\n",
    "            '10m_u_component_of_wind',\n",
    "            '10m_v_component_of_wind',\n",
    "            'mean_sea_level_pressure',\n",
    "            #'Sea_Ice_Concentration',\n",
    "        ],\n",
    "        'year': '2011',\n",
    "        'month': '11',\n",
    "        'day': days,\n",
    "        'time': time,\n",
    "    },\n",
    "    'download.grib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Converting the .grib file into .22 (NWS=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to where the .grib data was saved:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the .grib file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-18 13:10:20,928 WARNING Ignoring index file 'C:\\\\Users\\\\tmiesse\\\\Work\\\\adcirc-unswan\\\\inputs\\\\download.grib.88a63.idx' older than GRIB file\n",
      "2020-09-18 13:10:22,900 INFO missing from GRIB stream: 'directionNumber'\n",
      "2020-09-18 13:10:22,900 INFO missing from GRIB stream: 'frequencyNumber'\n",
      "2020-09-18 13:10:23,162 INFO missing from GRIB stream: 'directionNumber'\n",
      "2020-09-18 13:10:23,162 INFO missing from GRIB stream: 'frequencyNumber'\n",
      "2020-09-18 13:10:23,433 INFO missing from GRIB stream: 'directionNumber'\n",
      "2020-09-18 13:10:23,433 INFO missing from GRIB stream: 'frequencyNumber'\n"
     ]
    }
   ],
   "source": [
    "path = pl.Path(r'C:\\Users\\tmiesse\\Work\\adcirc-unswan\\inputs')\n",
    "file = 'download.grib'\n",
    "grib = xr.open_dataset(path / file, engine='cfgrib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the variables of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding box of domain\n",
    "lat1,lat2 = 44,88.5\n",
    "lon1,lon2 = -230, -85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = grib.coords['latitude'].values\n",
    "lon= grib.coords['longitude'].values\n",
    "time = grib.coords['time'].values[:]\n",
    "idx = np.where((lon1+360 >= lon)&(lon<=lon2+360))[0]\n",
    "idy = np.where((lat1 >= lat)&(lat<=lat2))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force2owi(file,dx,dy,dt,ilon,ilat,start,end,swlat,swlon,header,grib,lat1,lat2,lon1,lon2):\n",
    "    if file == 'fort.222':\n",
    "        u = grib.data_vars['u10'].values[:]\n",
    "        v = grib.data_vars['v10'].values[:]\n",
    "    elif file == 'fort.221':\n",
    "        prmsl = grib.data_vars['msl'].values[:]\n",
    "    elif file == 'fort.225':\n",
    "        ice = grib.data_vars['siconc'].values[:]\n",
    "    else:\n",
    "        raise TypeError('not correct forcing format')\n",
    "    \n",
    "    \n",
    "    lat = grib.coords['latitude'].values\n",
    "    lon= grib.coords['longitude'].values\n",
    "    idx = np.where((lon1+360 >= lon)&(lon<=lon2+360))[0]\n",
    "    idy = np.where((lat1 >= lat)&(lat<=lat2))[0]\n",
    "    with open(file,'w') as fin:\n",
    "        fin.write(header)\n",
    "        for t in range(len(dt[:])):\n",
    "            param ='iLat={:4d}iLong={:4d}DX={:6.4f}DY={:6.4f}SWLat={:8.5f}SWLon={:8.3f}DT={:12s}\\n'.format(ilat,ilon,dx,dy,swlat,swlon,str(dt[t].strftime('%Y%m%d%H%M')))#,width=8,prec=5)\n",
    "            fin.write(param)\n",
    "            i = 0\n",
    "            data = []\n",
    "            d1,d2 = [],[] \n",
    "            for y in idy[:]:\n",
    "                for x in idx[:]:\n",
    "                    if file == 'fort.222':\n",
    "                        windx = u[t,y,x]\n",
    "                        windy = v[t,y,x]\n",
    "                        d1.append(' {:{width}.{prec}f}'.format(windx,width=9,prec=4))\n",
    "                        d2.append(' {:{width}.{prec}f}'.format(windy,width=9,prec=4))\n",
    "                    elif file == 'fort.221':\n",
    "                        press = prmsl[t,y,x]/100\n",
    "                        data.append(' {:{width}.{prec}f}'.format(press,width=9,prec=4))\n",
    "                    elif file == 'fort.225':\n",
    "                        sea = ice[t,y,x]\n",
    "                        if np.isnan(sea):\n",
    "                            sea = -1.0\n",
    "                        else:\n",
    "                            sea =sea * 100\n",
    "                        data.append(' {:{width}.{prec}f}'.format(sea,width=9,prec=4))\n",
    "            i = 0\n",
    "            if file == 'fort.222':\n",
    "                for d in range(len(d1)):\n",
    "                    if (i == 7) :\n",
    "                        fin.write(d1[d]+'\\n')\n",
    "                        i=0\n",
    "                    elif (d+1>=len(d1)):\n",
    "                        fin.write(d2[d]+'\\n')\n",
    "                        i = 0\n",
    "                        for d in range(len(d2)):\n",
    "                            if (i == 7) :\n",
    "                                fin.write(d2[d]+'\\n')\n",
    "                                i=0\n",
    "                            elif (d+1>=len(d2)):\n",
    "                                fin.write(d2[d]+'\\n')\n",
    "                            else:\n",
    "                                fin.write(d2[d])\n",
    "                                i +=1\n",
    "                    else:\n",
    "                        fin.write(d1[d])\n",
    "                        i +=1\n",
    "            else:\n",
    "                for d in range(len(data)):\n",
    "                    if (i == 7) :\n",
    "                        fin.write(data[d]+'\\n')\n",
    "                        i=0\n",
    "                    elif (d+1>=len(data)):\n",
    "                        fin.write(data[d]+'\\n')\n",
    "                    else:\n",
    "                        fin.write(data[d])\n",
    "                        i +=1\n",
    "        #fin.write('\\n')\n",
    "    \n",
    "    print(f'amount of data {len(idx)*len(idy)} data is {len(data)}')\n",
    "    return print('generated owi formatted forcings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmiesse\\AppData\\Local\\Continuum\\miniconda3\\envs\\geospatial\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ts = [(t - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')  for t in time]\n",
    "ts2 = [datetime.datetime.utcfromtimestamp(t) for t in ts]\n",
    "dx = lon[1]-lon[0]\n",
    "dy = lat[0]-lat[1]\n",
    "ilon = len(idx)\n",
    "ilat = len(idy)\n",
    "start = ts2[0]\n",
    "end = ts2[-1]\n",
    "swlat = lat1\n",
    "swlon = lon1#+360\n",
    "header = 'Oceanweather WIN/PRE Format                            {:12s}   {:12s}\\n'.format(str(start.strftime('%Y%m%d%H')),str(end.strftime('%Y%m%d%H')))#     {}'\n",
    "dt = ts2\n",
    "file = 'fort.222'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of data 279777 data is 0\n",
      "generated owi formatted forcings\n"
     ]
    }
   ],
   "source": [
    "force2owi(file,dx,dy,dt[:],ilon,ilat,start,end,swlat,swlon,header,grib,lat1,lat2,lon1,lon2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geospatial]",
   "language": "python",
   "name": "conda-env-geospatial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
